#!/usr/bin/env python
# -*- encoding: utf-8 -*-
"""
HSLåº“çœŸå®è°ƒç”¨æ¨¡å¼å†…å­˜æ³„æ¼æ£€æµ‹
"""

import unittest
import gc
import psutil
import threading
import time
import sys
import os
import weakref
from unittest.mock import Mock, patch, MagicMock
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from tests.base import BaseTestCase


class HSLRealPatternMemoryTest(BaseTestCase):
    """HSLåº“çœŸå®ä½¿ç”¨æ¨¡å¼å†…å­˜æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        super().setUp()
        self.process = psutil.Process()
        self.memory_samples = []
        self.object_references = []
    
    def measure_memory(self, label=""):
        """æµ‹é‡å†…å­˜ä½¿ç”¨"""
        gc.collect()
        memory_mb = self.process.memory_info().rss / 1024 / 1024
        self.memory_samples.append((time.time(), memory_mb, label))
        if label:
            print(f"[{label}] å†…å­˜: {memory_mb:.2f}MB")
        return memory_mb
    
    def test_hsl_object_lifecycle_real_pattern(self):
        """æµ‹è¯•HSLå¯¹è±¡ç”Ÿå‘½å‘¨æœŸçš„çœŸå®æ¨¡å¼"""
        print("\nğŸ” æµ‹è¯•HSLå¯¹è±¡ç”Ÿå‘½å‘¨æœŸçœŸå®æ¨¡å¼...")
        
        initial_memory = self.measure_memory("Initial")
        
        # æ¨¡æ‹ŸçœŸå®çš„HSLä½¿ç”¨æ¨¡å¼ï¼šåˆ›å»ºå®¢æˆ·ç«¯ -> é•¿æ—¶é—´ä½¿ç”¨ -> å¼‚å¸¸é‡å»º
        for cycle in range(10):
            print(f"\n--- å‘¨æœŸ {cycle + 1} ---")
            
            # 1. åˆ›å»ºHSLå®¢æˆ·ç«¯ï¼ˆæ¨¡æ‹ŸMelsecA1ENetåˆ›å»ºï¼‰
            hsl_objects = []
            
            try:
                # æ¨¡æ‹Ÿåˆ›å»ºHSLå¯¹è±¡çš„å¼€é”€
                for i in range(5):  # æ¨¡æ‹Ÿå¤šä¸ªè¿æ¥
                    # åˆ›å»ºæ¨¡æ‹Ÿçš„HSLå¯¹è±¡ï¼ŒåŒ…å«ä¸€äº›å†…éƒ¨çŠ¶æ€
                    hsl_obj = {
                        'connection_id': f"conn_{cycle}_{i}",
                        'buffer': bytearray(1024),  # æ¨¡æ‹Ÿå†…éƒ¨ç¼“å†²åŒº
                        'state': {'connected': True, 'last_read': time.time()},
                        'read_cache': {},  # æ¨¡æ‹Ÿè¯»å–ç¼“å­˜
                        'write_queue': [],  # æ¨¡æ‹Ÿå†™å…¥é˜Ÿåˆ—
                        'error_log': [],   # æ¨¡æ‹Ÿé”™è¯¯æ—¥å¿—
                        'large_data': b'x' * 10240  # æ¨¡æ‹Ÿä¸€äº›å¤§æ•°æ®
                    }
                    hsl_objects.append(hsl_obj)
                
                self.measure_memory(f"Cycle_{cycle}_Created")
                
                # 2. æ¨¡æ‹Ÿé•¿æ—¶é—´ä½¿ç”¨ï¼ˆé¢‘ç¹è¯»å†™ï¼‰
                for operation in range(50):
                    for obj in hsl_objects:
                        # æ¨¡æ‹Ÿè¯»å–æ“ä½œçš„å‰¯ä½œç”¨
                        read_data = f"data_{operation}_{time.time()}"
                        obj['read_cache'][f"addr_{operation}"] = read_data
                        
                        # æ¨¡æ‹Ÿå†™å…¥é˜Ÿåˆ—æ“ä½œ
                        obj['write_queue'].append(f"write_{operation}")
                        
                        # æ¨¡æ‹Ÿé”™è¯¯æ—¥å¿—ç´¯ç§¯
                        if operation % 10 == 0:
                            obj['error_log'].append(f"warning_{operation}")
                        
                        # æ¸…ç†ä¸€äº›ç¼“å­˜ï¼ˆä½†å¯èƒ½ä¸å®Œå…¨ï¼‰
                        if len(obj['read_cache']) > 20:
                            # åªæ¸…ç†ä¸€åŠï¼Œæ¨¡æ‹Ÿä¸å®Œå…¨æ¸…ç†
                            keys = list(obj['read_cache'].keys())
                            for key in keys[:len(keys)//2]:
                                del obj['read_cache'][key]
                
                self.measure_memory(f"Cycle_{cycle}_Used")
                
                # 3. æ¨¡æ‹Ÿå¼‚å¸¸æƒ…å†µï¼ˆè¿™é‡Œå¯èƒ½æ˜¯æ³„æ¼ç‚¹ï¼‰
                if cycle % 3 == 0:  # æ¯3ä¸ªå‘¨æœŸæ¨¡æ‹Ÿä¸€æ¬¡å¼‚å¸¸
                    print(f"  æ¨¡æ‹Ÿå¼‚å¸¸é‡å»º...")
                    
                    # æ¨¡æ‹Ÿå¼‚å¸¸å‘ç”Ÿæ—¶çš„ä¸å®Œå…¨æ¸…ç†
                    for obj in hsl_objects:
                        # æ¸…ç†ä¸€äº›ä½†ä¸æ˜¯å…¨éƒ¨
                        obj['buffer'] = None  # æ¸…ç†ç¼“å†²åŒº
                        # ä½†æ˜¯å¿˜è®°æ¸…ç†å…¶ä»–ç¼“å­˜ï¼è¿™æ˜¯å¸¸è§çš„æ³„æ¼æº
                        # obj['read_cache'].clear()  # æ³¨é‡Šæ‰ï¼Œæ¨¡æ‹Ÿå¿˜è®°æ¸…ç†
                        # obj['write_queue'].clear()
                        # obj['error_log'].clear()
                    
                    # åˆ›å»ºæ–°å¯¹è±¡æ›¿ä»£æ—§å¯¹è±¡
                    hsl_objects = []  # åˆ é™¤å¼•ç”¨ï¼Œä½†å†…å­˜å¯èƒ½æ²¡æœ‰é‡Šæ”¾
                    
                    # é‡æ–°åˆ›å»º
                    for i in range(5):
                        new_obj = {
                            'connection_id': f"reconnect_{cycle}_{i}",
                            'buffer': bytearray(1024),
                            'state': {'connected': True, 'last_read': time.time()},
                            'read_cache': {},
                            'write_queue': [],
                            'error_log': [],
                            'large_data': b'x' * 10240
                        }
                        hsl_objects.append(new_obj)
                    
                    self.measure_memory(f"Cycle_{cycle}_Reconnected")
                
            finally:
                # æ¸…ç†ï¼ˆä½†å¯èƒ½ä¸å®Œå…¨ï¼‰
                for obj in hsl_objects:
                    if isinstance(obj, dict):
                        # æ¨¡æ‹Ÿä¸å®Œå…¨çš„æ¸…ç†
                        obj['buffer'] = None
                        # å…¶ä»–å­—æ®µå¯èƒ½æ²¡æœ‰æ¸…ç†
                
                del hsl_objects
                gc.collect()
                
                self.measure_memory(f"Cycle_{cycle}_Cleaned")
        
        final_memory = self.measure_memory("Final")
        
        # åˆ†æå†…å­˜å¢é•¿
        memory_increase = final_memory - initial_memory
        print(f"\nğŸ“Š å¯¹è±¡ç”Ÿå‘½å‘¨æœŸå†…å­˜åˆ†æ:")
        print(f"  åˆå§‹å†…å­˜: {initial_memory:.2f}MB")
        print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.2f}MB")
        print(f"  æ€»å†…å­˜å¢é•¿: {memory_increase:.2f}MB")
        print(f"  å¹³å‡æ¯å‘¨æœŸå¢é•¿: {memory_increase/10:.2f}MB")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾è‘—çš„å†…å­˜å¢é•¿
        if memory_increase > 15:
            print("  ğŸš¨ æ£€æµ‹åˆ°æ˜¾è‘—å†…å­˜å¢é•¿ï¼Œå¯èƒ½å­˜åœ¨æ³„æ¼")
            
            # åˆ†ææ³„æ¼æ¨¡å¼
            memory_timeline = [(sample[1] - initial_memory) for sample in self.memory_samples]
            
            # è®¡ç®—è¶‹åŠ¿
            if len(memory_timeline) > 5:
                first_quarter = memory_timeline[:len(memory_timeline)//4]
                last_quarter = memory_timeline[-len(memory_timeline)//4:]
                
                avg_first = sum(first_quarter) / len(first_quarter)
                avg_last = sum(last_quarter) / len(last_quarter)
                
                trend = avg_last - avg_first
                print(f"  å†…å­˜å¢é•¿è¶‹åŠ¿: {trend:.2f}MB")
                
                if trend > 5:
                    print("  ğŸ“ˆ å†…å­˜å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œå¯èƒ½æ˜¯ç´¯ç§¯æ€§æ³„æ¼")
        else:
            print("  âœ… å†…å­˜ä½¿ç”¨ç›¸å¯¹ç¨³å®š")
        
        return memory_increase
    
    def test_hsl_string_processing_real_leak(self):
        """æµ‹è¯•HSLå­—ç¬¦ä¸²å¤„ç†çš„çœŸå®æ³„æ¼æ¨¡å¼"""
        print("\nğŸ” æµ‹è¯•HSLå­—ç¬¦ä¸²å¤„ç†çœŸå®æ³„æ¼æ¨¡å¼...")
        
        initial_memory = self.measure_memory("String_Initial")
        
        # æ¨¡æ‹ŸçœŸå®çš„å­—ç¬¦ä¸²å¤„ç†åœºæ™¯
        accumulated_strings = []  # è¿™å¯èƒ½æ˜¯æ³„æ¼æº
        string_cache = {}         # è¿™ä¹Ÿå¯èƒ½æ˜¯æ³„æ¼æº
        
        for batch in range(20):
            print(f"  å¤„ç†æ‰¹æ¬¡ {batch + 1}...")
            
            batch_strings = []
            
            for i in range(100):
                # 1. æ¨¡æ‹ŸHSLè¿”å›çš„åŸå§‹å­—ç¬¦ä¸²
                raw_string = f"HSL_DATA_{batch}_{i}_" + "X" * 100 + "_END"
                
                # 2. æ¨¡æ‹Ÿå­—ç¬¦ä¸²å¤„ç†ï¼ˆè¿™é‡Œå¯èƒ½æœ‰æ³„æ¼ï¼‰
                # åˆ›å»ºå¤šä¸ªä¸­é—´å­—ç¬¦ä¸²å¯¹è±¡
                temp1 = str(raw_string)  # è½¬æ¢
                temp2 = temp1[4:64]      # åˆ‡ç‰‡
                temp3 = temp2.strip()    # æ¸…ç†
                
                # æ¨¡æ‹Ÿå­—ç¬¦æ£€æŸ¥
                has_alnum = any(char.isalnum() for char in temp3)
                
                if has_alnum:
                    # æ­£åˆ™è¡¨è¾¾å¼å¤„ç†ï¼ˆå¯èƒ½çš„æ³„æ¼ç‚¹ï¼‰
                    import re
                    temp4 = re.sub(r'\s+', '', temp3)
                    temp5 = re.sub(r'[^a-zA-Z0-9]', '_', temp4)
                    final_string = temp5[:30]  # æˆªæ–­
                else:
                    final_string = "None"
                
                # 3. å­˜å‚¨å¤„ç†ç»“æœï¼ˆå¯èƒ½çš„æ³„æ¼ç‚¹ï¼‰
                result_data = {
                    'original': raw_string,      # ä¿å­˜åŸå§‹å­—ç¬¦ä¸²
                    'processed': final_string,   # ä¿å­˜å¤„ç†ç»“æœ
                    'intermediate': [temp1, temp2, temp3],  # ä¿å­˜ä¸­é—´ç»“æœï¼
                    'metadata': {
                        'batch': batch,
                        'index': i,
                        'length': len(raw_string),
                        'has_alnum': has_alnum,
                        'timestamp': time.time()
                    }
                }
                
                batch_strings.append(result_data)
                
                # 4. ç¼“å­˜æœºåˆ¶ï¼ˆå¯èƒ½çš„æ³„æ¼ç‚¹ï¼‰
                cache_key = f"{batch}_{i}"
                string_cache[cache_key] = result_data  # ç¼“å­˜æ°¸è¿œä¸æ¸…ç†ï¼
            
            # 5. ç´¯ç§¯å­˜å‚¨ï¼ˆæ¨¡æ‹Ÿåº”ç”¨ç¨‹åºä¿å­˜æ•°æ®ï¼‰
            accumulated_strings.extend(batch_strings)
            
            # 6. ä¸å®Œå…¨çš„æ¸…ç†
            if batch % 5 == 0:
                # åªæ¸…ç†éƒ¨åˆ†æ•°æ®
                if len(accumulated_strings) > 300:
                    # åªä¿ç•™æœ€æ–°çš„200ä¸ª
                    accumulated_strings = accumulated_strings[-200:]
                
                # ç¼“å­˜æ¸…ç†ä¸å®Œå…¨
                if len(string_cache) > 500:
                    # åªåˆ é™¤ä¸€åŠçš„ç¼“å­˜
                    keys = list(string_cache.keys())
                    for key in keys[:len(keys)//2]:
                        del string_cache[key]
            
            if batch % 5 == 0:
                self.measure_memory(f"String_Batch_{batch}")
        
        # åˆ†æå­—ç¬¦ä¸²æ•°æ®
        print(f"\n  ç´¯ç§¯å­—ç¬¦ä¸²æ•°æ®: {len(accumulated_strings)} ä¸ª")
        print(f"  å­—ç¬¦ä¸²ç¼“å­˜å¤§å°: {len(string_cache)} ä¸ª")
        
        # è®¡ç®—æ•°æ®å¤§å°
        total_string_size = 0
        for item in accumulated_strings:
            if isinstance(item, dict):
                total_string_size += len(str(item.get('original', '')))
                total_string_size += len(str(item.get('processed', '')))
                if 'intermediate' in item:
                    for temp_str in item['intermediate']:
                        total_string_size += len(str(temp_str))
        
        print(f"  ä¼°è®¡å­—ç¬¦ä¸²æ•°æ®å¤§å°: {total_string_size / 1024 / 1024:.2f}MB")
        
        final_memory = self.measure_memory("String_Final")
        
        # å¼ºåˆ¶æ¸…ç†
        accumulated_strings.clear()
        string_cache.clear()
        gc.collect()
        
        cleaned_memory = self.measure_memory("String_Cleaned")
        
        memory_increase = final_memory - initial_memory
        cleanup_recovery = final_memory - cleaned_memory
        
        print(f"\nğŸ“Š å­—ç¬¦ä¸²å¤„ç†å†…å­˜åˆ†æ:")
        print(f"  åˆå§‹å†…å­˜: {initial_memory:.2f}MB")
        print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.2f}MB")
        print(f"  æ¸…ç†åå†…å­˜: {cleaned_memory:.2f}MB")
        print(f"  å†…å­˜å¢é•¿: {memory_increase:.2f}MB")
        print(f"  æ¸…ç†å›æ”¶: {cleanup_recovery:.2f}MB")
        
        if cleanup_recovery > 5:
            print("  ğŸš¨ æ¸…ç†åå›æ”¶äº†å¤§é‡å†…å­˜ï¼Œç¡®è®¤å­˜åœ¨å­—ç¬¦ä¸²æ³„æ¼")
        elif memory_increase > 10:
            print("  âš ï¸  å†…å­˜å¢é•¿è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨å­—ç¬¦ä¸²ç´¯ç§¯é—®é¢˜")
        else:
            print("  âœ… å­—ç¬¦ä¸²å¤„ç†å†…å­˜ä½¿ç”¨æ­£å¸¸")
        
        return memory_increase, cleanup_recovery
    
    def test_hsl_connection_pool_leak(self):
        """æµ‹è¯•HSLè¿æ¥æ± æ¨¡å¼çš„å†…å­˜æ³„æ¼"""
        print("\nğŸ” æµ‹è¯•HSLè¿æ¥æ± æ¨¡å¼å†…å­˜æ³„æ¼...")
        
        initial_memory = self.measure_memory("Pool_Initial")
        
        # æ¨¡æ‹Ÿè¿æ¥æ± 
        connection_pool = {}
        connection_stats = {}
        failed_connections = []  # å¤±è´¥è¿æ¥çš„ç´¯ç§¯
        
        for round_num in range(15):
            print(f"  è¿æ¥æ± è½®æ¬¡ {round_num + 1}...")
            
            # 1. åˆ›å»ºæ–°è¿æ¥
            for conn_id in range(5):
                connection_key = f"conn_{round_num}_{conn_id}"
                
                # æ¨¡æ‹Ÿè¿æ¥å¯¹è±¡
                connection = {
                    'id': connection_key,
                    'socket': Mock(),  # æ¨¡æ‹Ÿsocketå¯¹è±¡
                    'buffer': bytearray(2048),
                    'read_history': [],
                    'write_history': [],
                    'error_count': 0,
                    'created_time': time.time(),
                    'last_used': time.time(),
                    'stats': {'reads': 0, 'writes': 0, 'errors': 0}
                }
                
                connection_pool[connection_key] = connection
                connection_stats[connection_key] = []
            
            # 2. ä½¿ç”¨è¿æ¥è¿›è¡Œæ“ä½œ
            for operation in range(30):
                for conn_key, conn in list(connection_pool.items()):
                    try:
                        # æ¨¡æ‹Ÿè¯»å–æ“ä½œ
                        read_data = f"read_{operation}_" + "D" * 50
                        conn['read_history'].append(read_data)
                        conn['stats']['reads'] += 1
                        
                        # æ¨¡æ‹Ÿå†™å…¥æ“ä½œ
                        write_data = f"write_{operation}_" + "W" * 30
                        conn['write_history'].append(write_data)
                        conn['stats']['writes'] += 1
                        
                        # æ›´æ–°ç»Ÿè®¡
                        stat_entry = {
                            'timestamp': time.time(),
                            'operation': operation,
                            'memory_usage': len(conn['read_history']) + len(conn['write_history']),
                            'buffer_size': len(conn['buffer'])
                        }
                        connection_stats[conn_key].append(stat_entry)
                        
                        conn['last_used'] = time.time()
                        
                        # æ¨¡æ‹Ÿå¶å°”çš„é”™è¯¯
                        if operation % 20 == 0:
                            conn['error_count'] += 1
                            conn['stats']['errors'] += 1
                            error_info = {
                                'connection': conn_key,
                                'error': f"simulated_error_{operation}",
                                'timestamp': time.time(),
                                'context': conn.copy()  # è¿™é‡Œä¿å­˜äº†æ•´ä¸ªè¿æ¥ä¸Šä¸‹æ–‡ï¼
                            }
                            failed_connections.append(error_info)
                    
                    except Exception as e:
                        print(f"    è¿æ¥ {conn_key} æ“ä½œå¼‚å¸¸: {e}")
            
            # 3. ä¸å®Œå…¨çš„è¿æ¥æ¸…ç†
            if round_num % 3 == 0:
                print(f"    æ¸…ç†æ—§è¿æ¥...")
                
                # æŸ¥æ‰¾éœ€è¦æ¸…ç†çš„è¿æ¥
                current_time = time.time()
                connections_to_remove = []
                
                for conn_key, conn in connection_pool.items():
                    if current_time - conn['last_used'] > 1:  # 1ç§’æœªä½¿ç”¨
                        connections_to_remove.append(conn_key)
                
                # æ¸…ç†è¿æ¥ï¼ˆä½†å¯èƒ½ä¸å®Œå…¨ï¼‰
                for conn_key in connections_to_remove:
                    if conn_key in connection_pool:
                        conn = connection_pool[conn_key]
                        
                        # æ¸…ç†ç¼“å†²åŒº
                        conn['buffer'] = None
                        # ä½†æ˜¯å¿˜è®°æ¸…ç†å†å²è®°å½•ï¼
                        # conn['read_history'].clear()  # æ³¨é‡Šæ‰
                        # conn['write_history'].clear() # æ³¨é‡Šæ‰
                        
                        # ä»æ± ä¸­ç§»é™¤
                        del connection_pool[conn_key]
                        
                        # ä½†æ˜¯ç»Ÿè®¡æ•°æ®å¯èƒ½è¿˜åœ¨
                        # del connection_stats[conn_key]  # æ³¨é‡Šæ‰ï¼Œæ¨¡æ‹Ÿå¿˜è®°æ¸…ç†
            
            if round_num % 5 == 0:
                self.measure_memory(f"Pool_Round_{round_num}")
        
        # åˆ†æè¿æ¥æ± çŠ¶æ€
        print(f"\n  æ´»è·ƒè¿æ¥æ•°: {len(connection_pool)}")
        print(f"  ç»Ÿè®¡è®°å½•æ•°: {len(connection_stats)}")
        print(f"  å¤±è´¥è¿æ¥è®°å½•: {len(failed_connections)}")
        
        # è®¡ç®—æ•°æ®å¤§å°
        total_history_size = 0
        for conn in connection_pool.values():
            total_history_size += len(str(conn.get('read_history', [])))
            total_history_size += len(str(conn.get('write_history', [])))
        
        print(f"  è¿æ¥å†å²æ•°æ®å¤§å°: {total_history_size / 1024:.2f}KB")
        
        final_memory = self.measure_memory("Pool_Final")
        
        # å®Œå…¨æ¸…ç†
        for conn in connection_pool.values():
            if isinstance(conn, dict):
                conn.get('read_history', []).clear()
                conn.get('write_history', []).clear()
        
        connection_pool.clear()
        connection_stats.clear()
        failed_connections.clear()
        gc.collect()
        
        cleaned_memory = self.measure_memory("Pool_Cleaned")
        
        memory_increase = final_memory - initial_memory
        cleanup_recovery = final_memory - cleaned_memory
        
        print(f"\nğŸ“Š è¿æ¥æ± å†…å­˜åˆ†æ:")
        print(f"  åˆå§‹å†…å­˜: {initial_memory:.2f}MB")
        print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.2f}MB")
        print(f"  æ¸…ç†åå†…å­˜: {cleaned_memory:.2f}MB")
        print(f"  å†…å­˜å¢é•¿: {memory_increase:.2f}MB")
        print(f"  æ¸…ç†å›æ”¶: {cleanup_recovery:.2f}MB")
        
        if cleanup_recovery > 3:
            print("  ğŸš¨ è¿æ¥æ± å­˜åœ¨å†…å­˜æ³„æ¼")
        elif memory_increase > 8:
            print("  âš ï¸  è¿æ¥æ± å†…å­˜ä½¿ç”¨è¾ƒé«˜")
        else:
            print("  âœ… è¿æ¥æ± å†…å­˜ä½¿ç”¨æ­£å¸¸")
        
        return memory_increase, cleanup_recovery
    
    def test_comprehensive_hsl_leak_analysis(self):
        """ç»¼åˆHSLæ³„æ¼åˆ†æ"""
        print("\n" + "="*60)
        print("ğŸ”¬ HSLåº“çœŸå®ä½¿ç”¨æ¨¡å¼å†…å­˜æ³„æ¼ç»¼åˆåˆ†æ")
        print("="*60)
        
        results = {}
        
        # 1. å¯¹è±¡ç”Ÿå‘½å‘¨æœŸæµ‹è¯•
        print("\n1ï¸âƒ£ å¯¹è±¡ç”Ÿå‘½å‘¨æœŸæµ‹è¯•...")
        try:
            lifecycle_increase = self.test_hsl_object_lifecycle_real_pattern()
            results['lifecycle'] = lifecycle_increase
        except Exception as e:
            print(f"å¯¹è±¡ç”Ÿå‘½å‘¨æœŸæµ‹è¯•å¤±è´¥: {e}")
            results['lifecycle'] = None
        
        # 2. å­—ç¬¦ä¸²å¤„ç†æµ‹è¯•
        print("\n2ï¸âƒ£ å­—ç¬¦ä¸²å¤„ç†æµ‹è¯•...")
        try:
            string_increase, string_recovery = self.test_hsl_string_processing_real_leak()
            results['string'] = (string_increase, string_recovery)
        except Exception as e:
            print(f"å­—ç¬¦ä¸²å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
            results['string'] = None
        
        # 3. è¿æ¥æ± æµ‹è¯•
        print("\n3ï¸âƒ£ è¿æ¥æ± æµ‹è¯•...")
        try:
            pool_increase, pool_recovery = self.test_hsl_connection_pool_leak()
            results['pool'] = (pool_increase, pool_recovery)
        except Exception as e:
            print(f"è¿æ¥æ± æµ‹è¯•å¤±è´¥: {e}")
            results['pool'] = None
        
        # ç»¼åˆåˆ†æ
        print(f"\n" + "="*60)
        print(f"ğŸ“Š ç»¼åˆåˆ†æç»“æœ")
        print(f"="*60)
        
        critical_issues = []
        moderate_issues = []
        
        # åˆ†ææ¯ä¸ªæµ‹è¯•ç»“æœ
        if results['lifecycle'] is not None:
            if results['lifecycle'] > 15:
                critical_issues.append(f"å¯¹è±¡ç”Ÿå‘½å‘¨æœŸ: {results['lifecycle']:.2f}MB å¢é•¿")
            elif results['lifecycle'] > 8:
                moderate_issues.append(f"å¯¹è±¡ç”Ÿå‘½å‘¨æœŸ: {results['lifecycle']:.2f}MB å¢é•¿")
        
        if results['string'] is not None:
            increase, recovery = results['string']
            if recovery > 5:
                critical_issues.append(f"å­—ç¬¦ä¸²å¤„ç†: {increase:.2f}MB å¢é•¿, {recovery:.2f}MB å¯å›æ”¶")
            elif increase > 10:
                moderate_issues.append(f"å­—ç¬¦ä¸²å¤„ç†: {increase:.2f}MB å¢é•¿")
        
        if results['pool'] is not None:
            increase, recovery = results['pool']
            if recovery > 3:
                critical_issues.append(f"è¿æ¥æ± : {increase:.2f}MB å¢é•¿, {recovery:.2f}MB å¯å›æ”¶")
            elif increase > 8:
                moderate_issues.append(f"è¿æ¥æ± : {increase:.2f}MB å¢é•¿")
        
        # è¾“å‡ºç»“è®º
        if critical_issues:
            print(f"\nğŸš¨ å‘ç°ä¸¥é‡å†…å­˜æ³„æ¼é—®é¢˜:")
            for issue in critical_issues:
                print(f"  âŒ {issue}")
        
        if moderate_issues:
            print(f"\nâš ï¸  å‘ç°ä¸­ç­‰å†…å­˜é—®é¢˜:")
            for issue in moderate_issues:
                print(f"  âš¡ {issue}")
        
        if not critical_issues and not moderate_issues:
            print(f"\nâœ… æœªå‘ç°æ˜æ˜¾çš„å†…å­˜æ³„æ¼é—®é¢˜")
        
        # ç»™å‡ºå»ºè®®
        if critical_issues or moderate_issues:
            print(f"\nğŸ’¡ é’ˆå¯¹HSLåº“çš„ä¼˜åŒ–å»ºè®®:")
            print(f"  1. ğŸ”§ ç¡®ä¿åœ¨å¼‚å¸¸å¤„ç†æ—¶æ­£ç¡®å…³é—­HSLè¿æ¥")
            print(f"  2. ğŸ§¹ å®šæœŸæ¸…ç†è¯»å–ç¼“å­˜å’Œå†å²è®°å½•")
            print(f"  3. ğŸ“ é™åˆ¶å­—ç¬¦ä¸²å¤„ç†çš„ä¸­é—´å¯¹è±¡åˆ›å»º")
            print(f"  4. ğŸ”„ å®æ–½å®šæœŸçš„åƒåœ¾å›æ”¶æœºåˆ¶")
            print(f"  5. ğŸ“Š åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç›‘æ§å†…å­˜ä½¿ç”¨è¶‹åŠ¿")
            print(f"  6. âš¡ è€ƒè™‘ä½¿ç”¨å¯¹è±¡æ± æ¥ç®¡ç†HSLè¿æ¥")
            print(f"  7. ğŸ” ä½¿ç”¨æ›´ç²¾ç»†çš„å†…å­˜åˆ†æå·¥å…·è¿›è¡Œæ·±å…¥åˆ†æ")
        
        return results


if __name__ == '__main__':
    # è¿è¡ŒçœŸå®æ¨¡å¼çš„HSLå†…å­˜æ³„æ¼æ£€æµ‹æµ‹è¯•
    unittest.main(verbosity=2)