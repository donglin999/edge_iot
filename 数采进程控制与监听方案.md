# 数采进程控制与监听方案

## 1. 方案概述

### 1.1 核心思路
通过FastAPI后端实现进程管理服务，提供进程的启动、停止、重启、状态监控等功能，并通过WebSocket实现实时状态推送。

### 1.2 技术架构
```
前端 (Vue3) 
    ↓ HTTP/WebSocket
后端API (FastAPI)
    ↓ 进程管理
进程管理器 (ProcessManager)
    ↓ 子进程控制
数采进程 (ModbusTCP/OPCUA/MelsoftA1E等)



```

## 2. 后端进程管理设计

### 2.1 进程管理器核心类

```python
# process_manager.py
import asyncio
import subprocess
import psutil
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum
import json
import logging

class ProcessStatus(Enum):
    STOPPED = "stopped"
    STARTING = "starting"
    RUNNING = "running"
    STOPPING = "stopping"
    ERROR = "error"
    CRASHED = "crashed"

@dataclass
class ProcessInfo:
    name: str
    type: str  # modbus, opcua, melsoft等
    status: ProcessStatus
    pid: Optional[int] = None
    cpu_percent: float = 0.0
    memory_mb: float = 0.0
    start_time: Optional[float] = None
    restart_count: int = 0
    last_error: Optional[str] = None
    config_file: Optional[str] = None
    command: List[str] = None

class ProcessManager:
    def __init__(self):
        self.processes: Dict[str, ProcessInfo] = {}
        self.subprocesses: Dict[str, subprocess.Popen] = {}
        self.monitoring_task: Optional[asyncio.Task] = None
        self.logger = logging.getLogger(__name__)
        self.load_process_configs()
    
    def load_process_configs(self):
        """从配置文件加载进程定义"""
        # 从JSON配置文件加载进程定义
        config = {
            "modbus_collector": {
                "type": "modbus",
                "command": ["python", "-m", "apps.collector.modbustcp_influx"],
                "config_file": "configs/modbus_config.json",
                "auto_restart": True,
                "max_restarts": 5
            },
            "opcua_collector": {
                "type": "opcua", 
                "command": ["python", "-m", "apps.collector.opcua_influx"],
                "config_file": "configs/opcua_config.json",
                "auto_restart": True,
                "max_restarts": 5
            },
            "melsoft_collector": {
                "type": "melsoft",
                "command": ["python", "-m", "apps.collector.melseca1enet_influx"], 
                "config_file": "configs/melsoft_config.json",
                "auto_restart": False,
                "max_restarts": 3
            }
        }
        
        for name, cfg in config.items():
            self.processes[name] = ProcessInfo(
                name=name,
                type=cfg["type"],
                status=ProcessStatus.STOPPED,
                config_file=cfg.get("config_file"),
                command=cfg["command"]
            )
    
    async def start_process(self, process_name: str) -> bool:
        """启动指定进程"""
        if process_name not in self.processes:
            self.logger.error(f"进程 {process_name} 不存在")
            return False
            
        process_info = self.processes[process_name]
        
        if process_info.status == ProcessStatus.RUNNING:
            self.logger.warning(f"进程 {process_name} 已在运行")
            return True
            
        try:
            process_info.status = ProcessStatus.STARTING
            
            # 启动子进程
            proc = subprocess.Popen(
                process_info.command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            # 等待一段时间检查进程是否成功启动
            await asyncio.sleep(2)
            
            if proc.poll() is None:  # 进程仍在运行
                self.subprocesses[process_name] = proc
                process_info.pid = proc.pid
                process_info.status = ProcessStatus.RUNNING
                process_info.start_time = time.time()
                process_info.last_error = None
                
                self.logger.info(f"进程 {process_name} 启动成功, PID: {proc.pid}")
                return True
            else:
                # 进程启动失败
                stdout, stderr = proc.communicate()
                error_msg = stderr or stdout or "未知错误"
                process_info.status = ProcessStatus.ERROR
                process_info.last_error = error_msg
                
                self.logger.error(f"进程 {process_name} 启动失败: {error_msg}")
                return False
                
        except Exception as e:
            process_info.status = ProcessStatus.ERROR
            process_info.last_error = str(e)
            self.logger.error(f"启动进程 {process_name} 时发生异常: {e}")
            return False
    
    async def stop_process(self, process_name: str) -> bool:
        """停止指定进程"""
        if process_name not in self.processes:
            return False
            
        process_info = self.processes[process_name]
        
        if process_info.status != ProcessStatus.RUNNING:
            return True
            
        try:
            process_info.status = ProcessStatus.STOPPING
            
            if process_name in self.subprocesses:
                proc = self.subprocesses[process_name]
                
                # 优雅停止
                proc.terminate()
                
                # 等待进程结束，最多等待10秒
                try:
                    await asyncio.wait_for(
                        asyncio.create_task(self._wait_for_process_exit(proc)), 
                        timeout=10
                    )
                except asyncio.TimeoutError:
                    # 强制杀死
                    proc.kill()
                    await asyncio.sleep(1)
                
                del self.subprocesses[process_name]
            
            process_info.status = ProcessStatus.STOPPED
            process_info.pid = None
            process_info.start_time = None
            
            self.logger.info(f"进程 {process_name} 已停止")
            return True
            
        except Exception as e:
            self.logger.error(f"停止进程 {process_name} 时发生异常: {e}")
            return False
    
    async def restart_process(self, process_name: str) -> bool:
        """重启指定进程"""
        await self.stop_process(process_name)
        await asyncio.sleep(2)  # 等待2秒确保进程完全停止
        return await self.start_process(process_name)
    
    async def get_process_status(self, process_name: str) -> Optional[ProcessInfo]:
        """获取进程状态"""
        return self.processes.get(process_name)
    
    async def get_all_processes_status(self) -> List[ProcessInfo]:
        """获取所有进程状态"""
        return list(self.processes.values())
    
    async def start_monitoring(self):
        """开始进程监控"""
        if self.monitoring_task and not self.monitoring_task.done():
            return
            
        self.monitoring_task = asyncio.create_task(self._monitor_processes())
    
    async def stop_monitoring(self):
        """停止进程监控"""
        if self.monitoring_task:
            self.monitoring_task.cancel()
            try:
                await self.monitoring_task
            except asyncio.CancelledError:
                pass
    
    async def _monitor_processes(self):
        """监控进程状态"""
        while True:
            try:
                for process_name, process_info in self.processes.items():
                    if process_info.status == ProcessStatus.RUNNING:
                        await self._update_process_stats(process_name, process_info)
                        await self._check_process_health(process_name, process_info)
                
                await asyncio.sleep(5)  # 每5秒检查一次
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"监控进程时发生异常: {e}")
                await asyncio.sleep(5)
    
    async def _update_process_stats(self, process_name: str, process_info: ProcessInfo):
        """更新进程资源使用统计"""
        try:
            if process_info.pid:
                proc = psutil.Process(process_info.pid)
                process_info.cpu_percent = proc.cpu_percent()
                process_info.memory_mb = proc.memory_info().rss / 1024 / 1024
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            # 进程不存在或无权限访问
            await self._handle_process_crashed(process_name, process_info)
    
    async def _check_process_health(self, process_name: str, process_info: ProcessInfo):
        """检查进程健康状态"""
        if process_name in self.subprocesses:
            proc = self.subprocesses[process_name]
            if proc.poll() is not None:
                # 进程已退出
                await self._handle_process_crashed(process_name, process_info)
    
    async def _handle_process_crashed(self, process_name: str, process_info: ProcessInfo):
        """处理进程崩溃"""
        self.logger.warning(f"检测到进程 {process_name} 崩溃")
        
        process_info.status = ProcessStatus.CRASHED
        process_info.pid = None
        
        if process_name in self.subprocesses:
            del self.subprocesses[process_name]
        
        # 这里可以添加自动重启逻辑
        # if auto_restart and restart_count < max_restarts:
        #     await self.start_process(process_name)
    
    async def _wait_for_process_exit(self, proc):
        """等待进程退出"""
        while proc.poll() is None:
            await asyncio.sleep(0.1)

# 全局进程管理器实例
process_manager = ProcessManager()
```

### 2.2 FastAPI路由接口

```python
# api/routers/processes.py
from fastapi import APIRouter, HTTPException
from fastapi.responses import JSONResponse
from typing import List
import asyncio

from services.process_service import process_manager, ProcessInfo, ProcessStatus

router = APIRouter(prefix="/api/processes", tags=["processes"])

@router.get("/", response_model=List[dict])
async def get_all_processes():
    """获取所有进程状态"""
    processes = await process_manager.get_all_processes_status()
    return [
        {
            "name": p.name,
            "type": p.type,
            "status": p.status.value,
            "pid": p.pid,
            "cpu_percent": f"{p.cpu_percent:.1f}%",
            "memory_mb": f"{p.memory_mb:.1f}MB",
            "start_time": p.start_time,
            "restart_count": p.restart_count,
            "last_error": p.last_error
        }
        for p in processes
    ]

@router.get("/{process_name}")
async def get_process_status(process_name: str):
    """获取指定进程状态"""
    process_info = await process_manager.get_process_status(process_name)
    if not process_info:
        raise HTTPException(status_code=404, detail="进程不存在")
    
    return {
        "name": process_info.name,
        "type": process_info.type,
        "status": process_info.status.value,
        "pid": process_info.pid,
        "cpu_percent": f"{process_info.cpu_percent:.1f}%", 
        "memory_mb": f"{process_info.memory_mb:.1f}MB",
        "start_time": process_info.start_time,
        "restart_count": process_info.restart_count,
        "last_error": process_info.last_error
    }

@router.post("/{process_name}/start")
async def start_process(process_name: str):
    """启动指定进程"""
    success = await process_manager.start_process(process_name)
    if success:
        return {"message": f"进程 {process_name} 启动成功"}
    else:
        raise HTTPException(status_code=400, detail=f"进程 {process_name} 启动失败")

@router.post("/{process_name}/stop")
async def stop_process(process_name: str):
    """停止指定进程"""
    success = await process_manager.stop_process(process_name)
    if success:
        return {"message": f"进程 {process_name} 停止成功"}
    else:
        raise HTTPException(status_code=400, detail=f"进程 {process_name} 停止失败")

@router.post("/{process_name}/restart")
async def restart_process(process_name: str):
    """重启指定进程"""
    success = await process_manager.restart_process(process_name)
    if success:
        return {"message": f"进程 {process_name} 重启成功"}
    else:
        raise HTTPException(status_code=400, detail=f"进程 {process_name} 重启失败")

@router.post("/start-all")
async def start_all_processes():
    """启动所有进程"""
    processes = await process_manager.get_all_processes_status()
    results = []
    
    for process_info in processes:
        if process_info.status == ProcessStatus.STOPPED:
            success = await process_manager.start_process(process_info.name)
            results.append({
                "name": process_info.name,
                "success": success
            })
    
    return {"message": "批量启动完成", "results": results}

@router.post("/stop-all")
async def stop_all_processes():
    """停止所有进程"""
    processes = await process_manager.get_all_processes_status()
    results = []
    
    for process_info in processes:
        if process_info.status == ProcessStatus.RUNNING:
            success = await process_manager.stop_process(process_info.name)
            results.append({
                "name": process_info.name,
                "success": success
            })
    
    return {"message": "批量停止完成", "results": results}

@router.get("/stats/summary")
async def get_process_summary():
    """获取进程统计摘要"""
    processes = await process_manager.get_all_processes_status()
    
    total = len(processes)
    running = len([p for p in processes if p.status == ProcessStatus.RUNNING])
    stopped = len([p for p in processes if p.status == ProcessStatus.STOPPED])
    error = len([p for p in processes if p.status in [ProcessStatus.ERROR, ProcessStatus.CRASHED]])
    
    # 计算平均CPU使用率
    running_processes = [p for p in processes if p.status == ProcessStatus.RUNNING]
    avg_cpu = sum(p.cpu_percent for p in running_processes) / len(running_processes) if running_processes else 0
    
    return {
        "total_processes": total,
        "running_processes": running,
        "stopped_processes": stopped,
        "error_processes": error,
        "avg_cpu_usage": f"{avg_cpu:.1f}%"
    }
```

### 2.3 WebSocket实时推送

```python
# api/routers/websocket.py
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from typing import List
import asyncio
import json
import logging

from services.process_service import process_manager

router = APIRouter()

class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.logger = logging.getLogger(__name__)

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        self.logger.info(f"WebSocket连接建立，当前连接数: {len(self.active_connections)}")

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        self.logger.info(f"WebSocket连接断开，当前连接数: {len(self.active_connections)}")

    async def broadcast(self, message: dict):
        """广播消息给所有连接的客户端"""
        if not self.active_connections:
            return
            
        disconnected = []
        for connection in self.active_connections:
            try:
                await connection.send_text(json.dumps(message))
            except Exception as e:
                self.logger.error(f"发送WebSocket消息失败: {e}")
                disconnected.append(connection)
        
        # 清理断开的连接
        for conn in disconnected:
            self.disconnect(conn)

manager = ConnectionManager()

@router.websocket("/ws/processes")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    
    try:
        # 启动进程状态推送任务
        push_task = asyncio.create_task(push_process_status())
        
        while True:
            # 保持连接，处理客户端消息
            try:
                data = await asyncio.wait_for(websocket.receive_text(), timeout=1.0)
                message = json.loads(data)
                
                # 处理客户端请求
                if message.get("type") == "get_status":
                    processes = await process_manager.get_all_processes_status()
                    await websocket.send_text(json.dumps({
                        "type": "process_status",
                        "data": [
                            {
                                "name": p.name,
                                "type": p.type,
                                "status": p.status.value,
                                "pid": p.pid,
                                "cpu_percent": p.cpu_percent,
                                "memory_mb": p.memory_mb,
                                "start_time": p.start_time
                            }
                            for p in processes
                        ]
                    }))
                    
            except asyncio.TimeoutError:
                continue
            except WebSocketDisconnect:
                break
                
    except Exception as e:
        logging.error(f"WebSocket处理异常: {e}")
    finally:
        manager.disconnect(websocket)
        if 'push_task' in locals():
            push_task.cancel()

async def push_process_status():
    """定期推送进程状态"""
    while True:
        try:
            processes = await process_manager.get_all_processes_status()
            message = {
                "type": "process_status_update",
                "timestamp": asyncio.get_event_loop().time(),
                "data": [
                    {
                        "name": p.name,
                        "type": p.type,
                        "status": p.status.value,
                        "pid": p.pid,
                        "cpu_percent": p.cpu_percent,
                        "memory_mb": p.memory_mb,
                        "start_time": p.start_time,
                        "restart_count": p.restart_count
                    }
                    for p in processes
                ]
            }
            
            await manager.broadcast(message)
            await asyncio.sleep(5)  # 每5秒推送一次
            
        except asyncio.CancelledError:
            break
        except Exception as e:
            logging.error(f"推送进程状态异常: {e}")
            await asyncio.sleep(5)
```

## 3. 数采进程标准化

### 3.1 进程基类设计

```python
# apps/base/collector_base.py
import asyncio
import signal
import sys
import logging
from abc import ABC, abstractmethod
from typing import Dict, Any
import json

class BaseCollector(ABC):
    def __init__(self, config_file: str):
        self.config_file = config_file
        self.config = self.load_config()
        self.running = False
        self.logger = self.setup_logger()
        
        # 注册信号处理
        signal.signal(signal.SIGTERM, self.signal_handler)
        signal.signal(signal.SIGINT, self.signal_handler)
    
    def load_config(self) -> Dict[str, Any]:
        """加载配置文件"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"加载配置文件失败: {e}")
            sys.exit(1)
    
    def setup_logger(self) -> logging.Logger:
        """设置日志"""
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(logging.INFO)
        
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def signal_handler(self, signum, frame):
        """信号处理器"""
        self.logger.info(f"收到信号 {signum}，准备退出...")
        self.running = False
    
    @abstractmethod
    async def connect(self) -> bool:
        """连接设备"""
        pass
    
    @abstractmethod
    async def disconnect(self):
        """断开连接"""
        pass
    
    @abstractmethod
    async def collect_data(self) -> Dict[str, Any]:
        """采集数据"""
        pass
    
    @abstractmethod
    async def process_data(self, data: Dict[str, Any]):
        """处理数据"""
        pass
    
    async def run(self):
        """主运行循环"""
        self.logger.info("启动数据采集进程...")
        
        # 连接设备
        if not await self.connect():
            self.logger.error("连接设备失败")
            return
        
        self.running = True
        collect_interval = self.config.get('collect_interval', 5)
        
        try:
            while self.running:
                try:
                    # 采集数据
                    data = await self.collect_data()
                    if data:
                        await self.process_data(data)
                    
                    await asyncio.sleep(collect_interval)
                    
                except Exception as e:
                    self.logger.error(f"数据采集异常: {e}")
                    await asyncio.sleep(collect_interval)
                    
        except asyncio.CancelledError:
            self.logger.info("收到取消信号")
        finally:
            await self.disconnect()
            self.logger.info("数据采集进程已退出")

def run_collector(collector_class, config_file: str):
    """运行采集器"""
    collector = collector_class(config_file)
    
    try:
        asyncio.run(collector.run())
    except KeyboardInterrupt:
        pass
    except Exception as e:
        logging.error(f"运行采集器异常: {e}")
        sys.exit(1)
```

### 3.2 具体采集器实现示例

```python
# apps/collector/modbustcp_influx.py
import asyncio
from pymodbus.client.asynchronous.tcp import AsyncModbusTCPClient
from apps.base.collector_base import BaseCollector, run_collector

class ModbusTCPCollector(BaseCollector):
    def __init__(self, config_file: str):
        super().__init__(config_file)
        self.client = None
    
    async def connect(self) -> bool:
        """连接Modbus TCP设备"""
        try:
            host = self.config['modbus']['host']
            port = self.config['modbus']['port']
            
            self.client = AsyncModbusTCPClient(host, port)
            result = await self.client.connect()
            
            if result:
                self.logger.info(f"成功连接到 Modbus TCP 设备 {host}:{port}")
                return True
            else:
                self.logger.error(f"连接 Modbus TCP 设备失败 {host}:{port}")
                return False
                
        except Exception as e:
            self.logger.error(f"连接异常: {e}")
            return False
    
    async def disconnect(self):
        """断开连接"""
        if self.client:
            self.client.close()
            self.logger.info("已断开 Modbus TCP 连接")
    
    async def collect_data(self):
        """采集Modbus数据"""
        try:
            registers = self.config['modbus']['registers']
            data = {}
            
            for reg_config in registers:
                address = reg_config['address']
                count = reg_config.get('count', 1)
                tag_name = reg_config['tag']
                
                # 读取保持寄存器
                result = await self.client.read_holding_registers(address, count)
                
                if not result.isError():
                    data[tag_name] = result.registers[0] if count == 1 else result.registers
                else:
                    self.logger.warning(f"读取寄存器 {address} 失败")
            
            return data
            
        except Exception as e:
            self.logger.error(f"采集数据异常: {e}")
            return None
    
    async def process_data(self, data):
        """处理并存储数据到InfluxDB"""
        try:
            # 这里添加InfluxDB写入逻辑
            self.logger.info(f"采集到数据: {data}")
            
            # 示例：写入InfluxDB
            # await self.write_to_influxdb(data)
            
        except Exception as e:
            self.logger.error(f"处理数据异常: {e}")

if __name__ == "__main__":
    run_collector(ModbusTCPCollector, "configs/modbus_config.json")
```

## 4. 配置文件管理

### 4.1 进程配置文件

```json
// configs/process_config.json
{
  "processes": {
    "modbus_collector": {
      "type": "modbus",
      "command": ["python", "-m", "apps.collector.modbustcp_influx"],
      "config_file": "configs/modbus_config.json",
      "working_directory": ".",
      "auto_restart": true,
      "max_restarts": 5,
      "restart_delay": 10,
      "environment": {
        "PYTHONPATH": "."
      }
    },
    "opcua_collector": {
      "type": "opcua",
      "command": ["python", "-m", "apps.collector.opcua_influx"],
      "config_file": "configs/opcua_config.json",
      "working_directory": ".",
      "auto_restart": true,
      "max_restarts": 5,
      "restart_delay": 10
    },
    "melsoft_collector": {
      "type": "melsoft",
      "command": ["python", "-m", "apps.collector.melseca1enet_influx"],
      "config_file": "configs/melsoft_config.json",
      "working_directory": ".",
      "auto_restart": false,
      "max_restarts": 3,
      "restart_delay": 15
    }
  }
}
```

### 4.2 采集器配置文件示例

```json
// configs/modbus_config.json
{
  "modbus": {
    "host": "192.168.1.100",
    "port": 502,
    "timeout": 5,
    "unit_id": 1
  },
  "collect_interval": 5,
  "registers": [
    {
      "tag": "temperature",
      "address": 40001,
      "count": 1,
      "data_type": "float",
      "scale": 0.1,
      "unit": "°C"
    },
    {
      "tag": "pressure", 
      "address": 40002,
      "count": 1,
      "data_type": "float",
      "scale": 0.01,
      "unit": "MPa"
    }
  ],
  "influxdb": {
    "host": "localhost",
    "port": 8086,
    "database": "iot_data",
    "measurement": "modbus_data"
  }
}
```

## 5. 启动和配置

### 5.1 FastAPI应用启动

```python
# main.py
from fastapi import FastAPI
from contextlib import asynccontextmanager
import asyncio

from api.routers import processes, websocket
from services.process_service import process_manager

@asynccontextmanager
async def lifespan(app: FastAPI):
    # 启动时
    await process_manager.start_monitoring()
    yield
    # 关闭时
    await process_manager.stop_monitoring()

app = FastAPI(title="IoT数采系统API", lifespan=lifespan)

# 注册路由
app.include_router(processes.router)
app.include_router(websocket.router)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
```

### 5.2 系统服务配置

```ini
# /etc/systemd/system/iot-backend.service
[Unit]
Description=IoT Data Acquisition Backend
After=network.target

[Service]
Type=simple
User=iot
WorkingDirectory=/opt/iot-system/backend
Environment=PATH=/opt/iot-system/backend/venv/bin
ExecStart=/opt/iot-system/backend/venv/bin/python main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

## 6. 部署和监控

### 6.1 Docker部署

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["python", "main.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  iot-backend:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./configs:/app/configs
      - ./logs:/app/logs
    environment:
      - PYTHONPATH=/app
    restart: unless-stopped
    
  influxdb:
    image: influxdb:1.8
    ports:
      - "8086:8086"
    volumes:
      - influxdb_data:/var/lib/influxdb
    environment:
      - INFLUXDB_DB=iot_data
    restart: unless-stopped

volumes:
  influxdb_data:
```

## 7. 总结

这个方案提供了：

1. **完整的进程管理**: 启动、停止、重启、状态监控
2. **实时状态推送**: 通过WebSocket实时更新前端
3. **进程标准化**: 统一的进程基类和配置管理
4. **错误处理**: 完善的异常处理和日志记录
5. **自动监控**: 进程健康检查和资源监控
6. **部署支持**: Docker和系统服务部署方案

你可以基于这个方案开始实现具体的功能模块。需要我详细解释任何部分吗？